{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series - multivariate prediction, data preprocessing\n",
    "\n",
    "In this example, we will use `pandas` to load and prepare dataset for multivariate prediction.\n",
    "\n",
    "The dataset is from Prague airport daily weather measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datetime import date\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's prepare some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = {str(y) for y in range(1, 32)}\n",
    "months = dict(zip(\n",
    "    ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'),\n",
    "    range(1, 13)\n",
    "))            \n",
    "years = {str(y) for y in range(1996, 2018)}\n",
    "\n",
    "rain_flags = ['Thunderstorm', 'Rain', 'Hail', 'Snow']\n",
    "\n",
    "def triple(col_name):\n",
    "    return [col_name + '[hi]', col_name + '[av]', col_name + '[lo]']\n",
    "\n",
    "columns = ['Temp', 'DPoint', 'Humidity', 'SLPress', 'Vis', 'Wind']\n",
    "all_columns = [t for col in columns for t in triple(col)] + ['Precip[sum]', 'Precip[0-1]']\n",
    "\n",
    "def floatOrNaN(token):\n",
    "    try:\n",
    "        return float(token)\n",
    "    except ValueError:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the set of all columns for the whole database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's prepare a method for loading dataset into pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_dataframe(file_path):\n",
    "    print('Loading: %s... ' % file_path, end='')\n",
    "    with open(file_path) as file:\n",
    "        lines = [line for line in file]\n",
    "\n",
    "    if not lines[-1].endswith('\\n'):\n",
    "        lines[-1] = lines[-1] + '\\n'\n",
    "\n",
    "    tokens = re.split('[\\t\\n]', lines[0])[:-1]    \n",
    "    if tokens[0] not in years:\n",
    "        raise ValueError('Year expected: %s' % tokens[0])    \n",
    "    current_year = tokens[0]\n",
    "\n",
    "    tokens = re.split('[\\t\\n]', lines[1])[:-1]    \n",
    "    if tokens[0] not in months:\n",
    "        raise ValueError('Month expected: %s' % tokens[0])    \n",
    "    current_month = tokens[0]\n",
    "\n",
    "    dates = []\n",
    "    values = []\n",
    "\n",
    "    for line in lines[2:]:        \n",
    "        tokens = re.split('[\\t\\n]', line)[:-1]    \n",
    "        if tokens[0] in years:\n",
    "            current_year = tokens[0]\n",
    "        elif tokens[0] in months:\n",
    "            current_month = tokens[0]\n",
    "        elif tokens[0] in days:\n",
    "            dates.append(date(int(current_year), months[current_month], int(tokens[0])))            \n",
    "            has_rain = any(rf in tokens[-1] for rf in rain_flags)\n",
    "            numbers = np.array([floatOrNaN(token) for token in tokens[1:-1]] + [1 if has_rain else 0])\n",
    "            if numbers.shape[0] != 20:\n",
    "                raise ValueError('Invalid row: %s %s' % (current_month, \" \".join(tokens)))\n",
    "            values.append(numbers)\n",
    "        else:\n",
    "            raise ValueError('Unexpected token: %s' % tokens[0])\n",
    "            \n",
    "    try:\n",
    "        df = pd.DataFrame(np.stack(values), columns=all_columns, index=pd.DatetimeIndex(dates, freq='D', verify_integrity=True))\n",
    "        print(\"%d rows.\" % len(values))\n",
    "        return df\n",
    "    except:\n",
    "        print('%d rows. Warning! missing rows.' % len(values))\n",
    "        return pd.DataFrame(np.stack(values), columns=all_columns, index=pd.DatetimeIndex(dates, freq='D', verify_integrity=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into a list of dataframes, one dataframe per year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/weather/LKPR/'\n",
    "files = sorted([filenames for dirpath, dirnames, filenames in os.walk(PATH)][0])\n",
    "\n",
    "df_years = []\n",
    "\n",
    "for file in sorted(files):\n",
    "    df_years.append(load_to_dataframe(PATH + file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some missing values (more then a half year gap) in the data. \n",
    "\n",
    "Let's take only data after the gap and make one long sequence out of all consecutive years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_years[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needs to be normalized (again, column-wise normalization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min = df.min()\n",
    "df_max = df.max()\n",
    "df_norm = (df - df_min) / (df_max - df_min)\n",
    "\n",
    "data_bounds = pd.concat((df_min, df_max), axis=1)\n",
    "data_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data selection\n",
    "\n",
    "For our prediction we are going to select the following columns:\n",
    "\n",
    "- **average temperature** (cont. value)\n",
    "- **averate temperature of the dew point** (cont. value)\n",
    "- **sea level pressure** (cont. value)\n",
    "- **precipitation** (binary yes/no)\n",
    "\n",
    "Notice that we would rather use rolling average of the values (except for precipitation) to mitigate hidden variables (sunlight etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Temp[av]', 'DPoint[av]', 'SLPress[av]']\n",
    "selected_df = pd.concat((df_norm[c] for c in selected_columns), axis=1)\n",
    "average = selected_df.rolling(window=5, center=True).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see our data for the last year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_date = '2017-01-01'\n",
    "end_date = '2017-12-31'\n",
    "\n",
    "plt.figure(figsize = (25, 6))\n",
    "plt.plot(selected_df[start_date:end_date], 'silver')\n",
    "plt.plot(average[start_date:end_date])\n",
    "plt.plot(df_norm['Precip[0-1]'][start_date:end_date], 'oc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, concatenate continuous value columns with precipitaion and store the dataset for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.concat((average, df_norm['Precip[0-1]']), axis=1).dropna()\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.to_pickle('../data/weather/ts_temp_dp_press.p')\n",
    "data_bounds.to_pickle('../data/weather/data_bounds.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
